# ğŸ§  Transformer - Projet Attention

## ğŸ“ Projet de spÃ©cialisation - Holberton School

Ce projet consiste Ã  construire, pas Ã  pas, un **modÃ¨le Transformer complet** tel que prÃ©sentÃ© dans le cÃ©lÃ¨bre article ["Attention Is All You Need"](https://arxiv.org/abs/1706.03762).

Lâ€™objectif est dâ€™implÃ©menter les composants fondamentaux dâ€™un **modÃ¨le de traduction automatique (seq2seq)** basÃ© sur des mÃ©canismes dâ€™attention et sans RNN, 100% en TensorFlow.

---

## ğŸ“š Ce que vous allez apprendre

âœ… CrÃ©er un **RNN Encoder** et un **RNN Decoder** avec attention  
âœ… ImplÃ©menter le **Self Attention** (scaled dot product attention)  
âœ… Concevoir la **Multi-Head Attention**  
âœ… Ajouter des **encodages positionnels**  
âœ… Construire des **blocs Encoder / Decoder**  
âœ… Assembler un modÃ¨le **Transformer complet** (Encodeur + DÃ©codeur)  
âœ… Comprendre les **masques** utilisÃ©s dans le NLP

---

## ğŸ› ï¸ Technologies utilisÃ©es

- Python 3.9
- TensorFlow 2.15
- NumPy 1.25.2
- Normes [pycodestyle 2.11.1](https://pycodestyle.readthedocs.io/)
- Ubuntu 20.04 (WSL compatible)

---

## ğŸ“ Structure du projet

| Fichier                       | Description                                      |
|------------------------------|--------------------------------------------------|
| `0-rnn_encoder.py`           | Encodeur RNN classique (GRU)                     |
| `1-self_attention.py`        | MÃ©canisme dâ€™attention par produit scalaire      |
| `2-rnn_decoder.py`           | DÃ©codeur RNN avec attention                     |
| `4-positional_encoding.py`   | Encodages de position sinusoÃ¯daux               |
| `5-sdp_attention.py`         | Attention par produit scalaire mis Ã  lâ€™Ã©chelle  |
| `6-multihead_attention.py`   | Attention multi-tÃªte                            |
| `7-transformer_encoder_block.py` | Bloc dâ€™encodeur Transformer               |
| `8-transformer_decoder_block.py` | Bloc de dÃ©codeur Transformer               |
| `9-transformer_encoder.py`   | Encodeur complet (empilement de blocs)          |
| `10-transformer_decoder.py`  | DÃ©codeur complet (empilement de blocs)          |
| `11-transformer.py`          | ModÃ¨le Transformer complet                      |
| `README.md`                  | Documentation du projet                         |

---


## âœ… Bonnes pratiques respectÃ©es

* ğŸ“ Tous les fichiers respectent `pycodestyle`
* ğŸ“˜ Chaque module, classe et fonction est documentÃ©
* ğŸš« Aucun import non autorisÃ©
* ğŸ§± Code modulaire, rÃ©utilisable, structurÃ©
